{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hawaiian-petersburg",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-syracuse",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-revelation",
   "metadata": {},
   "source": [
    "# **Sieć Bayesowska** (ang. *Bayesian Network*)\n",
    "to probabilistyczny model grafowy, w którym zmienne losowe i ich warunkowe niezależności reprezentowane sa za pomocą **skierowanego acyklicznego grafu**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-complaint",
   "metadata": {},
   "source": [
    "# Warunkowa niezależność\n",
    "**Przykład**:\n",
    "Rozważmy model składający się z następujących zmiennych losowych:\n",
    "- $\\text{MIT}$ - akcpetacja studenta na MIT\n",
    "- $\\text{Stanford}$ - akceptacja studenta na Stanford\n",
    "\n",
    "Pomimo, że zmienne dotyczą akceptacji na różne uczelnie, to nie możemy założyć, że są niezależne. Jeżeli student został zaakceptowany na MIT, to znaczy że ma bardzo dobre wyniki i są duże szanse, że dostanie się również na Stanford. \n",
    "$$ P(\\text{MIT}, \\text{Stanford}) \\neq P(\\text{MIT}) \\cdot P(\\text{Stanford}), $$\n",
    "gdzie $P(\\text{MIT})$ i $P(\\text{Stanford})$ to funkcje masy prawdopobieństwa dla odpowiednich zmiennych.\n",
    "Możemy wprowadzić dodatkową zmienną losową:\n",
    "- $\\text{GPA}$ - średnia ocen\n",
    "i założyć, że akceptacja na studia zależy tylko od średniej studenta. Wtedy\n",
    "$$ P(\\text{MIT}, \\text{Stanford} | \\text{GPA}=A) = P(\\text{MIT}| \\text{GPA}=A) \\cdot P(\\text{Stanford}| \\text{GPA}=A) $$\n",
    "i w konsekwencji również między innymi\n",
    "$$ P(\\text{MIT} | \\text{Stanford}=1, \\text{GPA}=A) = P(\\text{MIT} | \\text{GPA}=A).$$\n",
    "\n",
    "Mówimy, że $\\text{MIT}$ jest **warunkowo niezależne** od $\\text{Stanford}$ przy **danym**  $\\text{GPA}$ i oznaczamy jako\n",
    "$$ \\text{MIT} \\perp \\text{Stanford} | \\text{GPA}.$$\n",
    "\n",
    "Wykorzystanie wiedzy (intuicji) o warunkowych niezależnościach w danej przestrzeni probabilistycznej umożliwi wyrażenie rozkładu łącznego za pomocą reguły łańcuchowej i w konsekwencji sieci bayesowskiej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-copying",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Rozważmy model dotyczący kandydata na studia wyższe w USA, czyli absolwenta szkoły wyższej. Jego aplikacja będzie oceniana na podstawie wyniku z testu kompetencji (**SAT**) oraz treści listu polecającego od nauczyciela (**Letter**). Podstawową cechą kandydata jest jego inteligencja (**Intelligence**), ale nauczyciel ocenia ją na podstawie oceny kończowej z jego kursu (**Grade**), na którą wpływa również trudność pytań zaliczeniowych (**Difficulty**).\n",
    "\n",
    "Zdefiniumy poniżej zmienne występujące w modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty = 'Difficulty'\n",
    "intelligence = 'Intelligence'\n",
    "grade = 'Grade'\n",
    "sat = 'SAT'\n",
    "letter = 'Letter'\n",
    "\n",
    "random_variables = [\n",
    "    difficulty,\n",
    "    intelligence,\n",
    "    grade,\n",
    "    sat,\n",
    "    letter,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import binom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-lincoln",
   "metadata": {},
   "source": [
    "Ile jest Sieci Bayesowskich na tych zmiennych losowych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_dags(n):\n",
    "    '''Based on https://en.wikipedia.org/wiki/Directed_acyclic_graph#Combinatorial_enumeration'''\n",
    "    def _internal(n_int, k):\n",
    "        assert k <= n_int\n",
    "        return ((-1)**(k-1)) * int(binom(n_int, k)) * (2**(k*(n_int - k))) * number_of_dags(n_int - k)\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return sum([_internal(n, k) for k in range(1, n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_dags(len(random_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-junction",
   "metadata": {},
   "source": [
    "Propozycja:\n",
    "\n",
    "- **Difficulty** jest niezależne od pozostałych zmiennych, a jedynie na nie wpływa; poza modelem istnieją czynniki wpływające na trudność, ale ich nie obserwujemy\n",
    "- **Intelligence** to kolejna zmienna, która jest niezależne od pozostałych, będzie natomiast na nie wpływać (pośrednio, bądź bezpośrednio)\n",
    "- **Grade** jest bezpośrednio zależne od wyżej wymienionych czynników\n",
    "- **SAT** (Scholastic Assessment Test) jest ustandaryzowanym egzaminem państwowym, więc jedynym co wpływa na wynik są umiejętności kandydata (w naszym modelu zawarte w zmiennej Intelligence)\n",
    "- **Letter** to subiektywna ocena prowadzącego na temat ucznia, można się jednak spodziewać że nie jest ona wnikliwa, a jedynie oparta na ocenie z kursu.\n",
    "\n",
    "Zapiszmy powyższe zależności w postaci grafu skierowanego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "# skierowany model!\n",
    "bn = BayesianModel([\n",
    "    (difficulty, grade),\n",
    "    (intelligence, grade),\n",
    "    (intelligence, sat),\n",
    "    (grade, letter),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# requires graphviz and graphviz-dev installed in your operating system\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "pos=graphviz_layout(bn, prog='dot')\n",
    "nx.draw(\n",
    "    bn,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color='white',\n",
    "    edgecolors='black',\n",
    "    node_size=5000,\n",
    "    arrowsize=20,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-gateway",
   "metadata": {},
   "source": [
    "# D-separacja\n",
    "Warunkowa niezależność jest podstawowym narzędziem we wnioskowaniu w Sieciach Bayesowskich - przy spełnieniu odpowidnich warunków pozwala faktoryzować rozkłady łączne w iloczyn rozkładów brzegowych. W skomplikowanych modelach probabilistycznych, gdzie dwa wierzchołki połączone są kilkoma ścieżkami identyfikacja waunkowych niezależność nie jest trywialna. Rozwiązaniem jest zaproponowanie **algorytmu D-separacji**.\n",
    "\n",
    "Wprowadzenie do D-separacji: [http://web.mit.edu/jmn/www/6.034/d-separation.pdf](http://web.mit.edu/jmn/www/6.034/d-separation.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bn.is_active_trail(intelligence, letter))\n",
    "print(bn.is_active_trail(intelligence, letter, observed=[grade]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bn.is_active_trail(intelligence, difficulty))\n",
    "print(bn.is_active_trail(intelligence, difficulty, observed=[grade]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.active_trail_nodes(difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.active_trail_nodes(difficulty, observed=[grade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.local_independencies(difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.local_independencies(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.get_independencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-fireplace",
   "metadata": {},
   "source": [
    "# Tabularyczny Warunkowy Rozkład Prawdopobieństwa\n",
    "Warunkowe rozkłady na zmiennych dyskretnych możemy zapisać za pomocą tabeli, tworząc Tabularyczny Warunkowy Rozkład Prawdopobieństwa. Jest to podstawowy rodzaj rozkładu w pgmpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('figures/SAT_bayesian_network.png')\n",
    "# Source: Koller, D., & Friedman, N. (2015). Probabilistic graphical models. In Studies in Systems, Decision and Control (Vol. 11). https://doi.org/10.1007/978-3-319-11325-8_2 Fig. 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-campus",
   "metadata": {},
   "source": [
    "From https://pgmpy.org/_modules/pgmpy/factors/discrete/CPD.html:\n",
    "\n",
    "For a distribution of P(grade|diff, intel):\n",
    "\n",
    "    |diff    |      easy          |    hard          |\n",
    "    | ----- | --- | ---- | ----- | ---- | -- | ---- |\n",
    "    |intel  |dumb |  avg | smart | dumb |avg |smart |\n",
    "    |gradeA |0.1  |  0.1 |  0.1  | 0.1  |0.1 | 0.1  |\n",
    "    |gradeB |0.1  |  0.1 |  0.1  | 0.1  |0.1 | 0.1  |\n",
    "    |gradeC |0.8  |  0.8 |  0.8  | 0.8  |0.8 | 0.8  |\n",
    "\n",
    "values should be:\n",
    "\n",
    "    [[0.1,0.1,0.1,0.1,0.1,0.1],\n",
    "    [0.1,0.1,0.1,0.1,0.1,0.1],\n",
    "    [0.8,0.8,0.8,0.8,0.8,0.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpds = {\n",
    "    difficulty: TabularCPD(\n",
    "        variable=difficulty,\n",
    "        variable_card=2,\n",
    "        values=[[0.6], [0.4]]\n",
    "    ),\n",
    "    intelligence: TabularCPD(\n",
    "        variable=intelligence,\n",
    "        variable_card=2,\n",
    "        values=[[0.7], [0.3]]\n",
    "    ),\n",
    "    grade: TabularCPD(\n",
    "        variable=grade,\n",
    "        variable_card=3,\n",
    "        evidence=[difficulty, intelligence],\n",
    "        evidence_card=[2, 2],\n",
    "        values=[\n",
    "            [0.3, 0.9, 0.05, 0.5],\n",
    "            [0.4, 0.08, 0.25, 0.3],\n",
    "            [0.3, 0.02, 0.7, 0.2],\n",
    "        ]\n",
    "    ),\n",
    "    sat: TabularCPD(\n",
    "        variable=sat,\n",
    "        variable_card=2,\n",
    "        evidence=[intelligence],\n",
    "        evidence_card=[2],\n",
    "        values=[\n",
    "            [0.95, 0.2],\n",
    "            [0.05, 0.8],\n",
    "        ]\n",
    "    ),\n",
    "    letter: TabularCPD(\n",
    "        variable=letter,\n",
    "        variable_card=2,\n",
    "        evidence=[grade],\n",
    "        evidence_card=[3],\n",
    "        values=[\n",
    "            [0.1, 0.4, 0.99],\n",
    "            [0.9, 0.6, 0.01],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associating the parameters with the model structure.\n",
    "bn.add_cpds(*cpds.values())\n",
    "\n",
    "# Checking if the cpds are valid for the model.\n",
    "bn.check_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-incidence",
   "metadata": {},
   "source": [
    "# Wnioskowanie w sieciach bayesowskich\n",
    "Zastosowaniem dla probabilistycznych modeli grafowych jest **wnioskowanie**, czyli odpowiadanie na **zapytania** na podstawie łącznego rozkładu prawdopobieństwa. Wyszczególnić można dwa podstawowe typy zapytań:\n",
    "1. Zapytanie o rozkład\n",
    "\n",
    "   Celem jest odnaleźć (obliczyć)\n",
    "   $$ P(Y | E=e),$$\n",
    "   gdzie $E$ to podzbiór obserwowanych zmiennych o wartościach $e$, a $Y$ to podzbiór zmiennych dla których szukamy rozkładu posterior. Model może składać się z większej liczby zmiennych niż $Y$ i $E$, które należy zmarginalizować w tym zapytaniu.\n",
    "   \n",
    "2. Zapytanie o najbardziej prawdopodobną wartość\n",
    "\n",
    "   Niech $W = X - E$, gdzie $X$ to zbiór wszystkich zmiennych w modelu, a $E$ to zbiór zmiennych obserwowanych o wartościach $e$. Zapytanie to:\n",
    "   $$ MAP(W | E=e) = \\arg \\max_w P(W=w, E=e).$$\n",
    "   \n",
    "Należy zwrócić uwagę na różnicę pomiędzy tymi dwoma rodzajami zapytań. W 2. pytamy o najbardziej prawdopodobną konfigurajcę całego modelu przy obserwacji $e$. Natomiast 1. dotyczy rozkładu (na podstawie, którego łatwo możemy obliczyć MAP) łącznego podzbioru zmiennych w sieci przy obserwacji $e$, gdzie pozostałe elementy modelu zostają wymarginalizowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination, BeliefPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-phone",
   "metadata": {},
   "source": [
    "Dwie metody do wnioskowanie *dokładnego*:\n",
    "- Variable Elimination\n",
    "- Belief Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_infer = VariableElimination(bn)\n",
    "bp_infer = BeliefPropagation(bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-cancellation",
   "metadata": {},
   "source": [
    "Jaki jest rozkład brzegowy `sat` gdy `grade=1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ve_infer.query(variables=[sat], evidence={grade: 1}))\n",
    "print(bp_infer.query(variables=[sat], evidence={grade: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-saturday",
   "metadata": {},
   "source": [
    "Jaki jest rozkład łączny `sat` i `letter` gdy `grade=1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ve_infer.query(variables=[sat, letter], evidence={grade: 1}, joint=True))\n",
    "# print(bp_infer.query(variables=[sat, letter], evidence={grade: 1}, joint=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-finder",
   "metadata": {},
   "source": [
    "Jaki jest rozkład brzegowy listy zmiennych gdy `grade=1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, pd in ve_infer.query(variables=[sat, letter], evidence={grade: 1}, joint=False).items():\n",
    "    print(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-deadline",
   "metadata": {},
   "source": [
    "Jaka jest najbardziej prawdopodobna konfiguracja gdy `intelligence=0`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_infer.map_query(evidence={intelligence: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_infer.map_query(variables=[sat], evidence={intelligence: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-minimum",
   "metadata": {},
   "source": [
    "Jakie jest prawdopobieństwo takiego zdarzenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_infer.max_marginal(variables=[letter, grade, sat, difficulty], evidence={intelligence: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-ghost",
   "metadata": {},
   "source": [
    "# Ale skąd CPDs w rzeczywistości? Z danych!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-plaza",
   "metadata": {},
   "source": [
    "Na początek wygenerujmy zbiór danych na podstawie modelu ze znanymi rozkładami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.sampling import BayesianModelSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = BayesianModelSampling(bn).forward_sample(size=10_000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-reviewer",
   "metadata": {},
   "source": [
    "Stwórzmy nowy model o tej samej strukturze, jak poprzedni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bn = BayesianModel(ebunch=bn.edges())\n",
    "new_bn.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bn.get_cpds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-grounds",
   "metadata": {},
   "source": [
    "Dostępne estymatory:\n",
    "- Maximum Likelihood Estimator\n",
    "- Bayesian Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-timer",
   "metadata": {},
   "source": [
    "MLE nie ma żadnych parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle = MaximumLikelihoodEstimator(model=new_bn, data=df)\n",
    "print(mle.estimate_cpd(node=intelligence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-beverage",
   "metadata": {},
   "source": [
    "CPDs dla wszystkich wierzchołków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle.get_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-banana",
   "metadata": {},
   "source": [
    "Dla Bayesian Estimator musimy określić prior:\n",
    ">        prior_type: 'dirichlet', 'BDeu', or 'K2' string indicting which type of prior to use for the model parameters.\n",
    "            - If 'prior_type' is 'dirichlet', the following must be provided:\n",
    "                'pseudo_counts' = dirichlet hyperparameters; a single number or a dict containing, for each\n",
    "                 variable, a 2-D array of the shape (node_card, product of parents_card) with a \"virtual\"\n",
    "                 count for each variable state in the CPD, that is added to the state counts.\n",
    "                 (lexicographic ordering of states assumed)\n",
    "            - If 'prior_type' is 'BDeu', then an 'equivalent_sample_size'\n",
    "                must be specified instead of 'pseudo_counts'. This is equivalent to\n",
    "                'prior_type=dirichlet' and using uniform 'pseudo_counts' of\n",
    "                `equivalent_sample_size/(node_cardinality*np.prod(parents_cardinalities))` for each node.\n",
    "                'equivalent_sample_size' can either be a numerical value or a dict that specifies\n",
    "                the size for each variable separately.\n",
    "            - A prior_type of 'K2' is a shorthand for 'dirichlet' + setting every pseudo_count to 1,\n",
    "                regardless of the cardinality of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "be = BayesianEstimator(new_bn, df)\n",
    "print(be.estimate_cpd(\n",
    "    node=intelligence,\n",
    "    prior_type='dirichlet',\n",
    "    pseudo_counts=2\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(be.estimate_cpd(\n",
    "    node=intelligence,\n",
    "    prior_type='BDeu',\n",
    "    equivalent_sample_size=5,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-underwear",
   "metadata": {},
   "source": [
    "Możemy też zastosować metodę `fit` na modelu by uzyskać CPD przypisane do odpowiednich zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bn.fit(data=df, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=2)\n",
    "new_bn.get_cpds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-illinois",
   "metadata": {},
   "source": [
    "# A skąd struktura modelu? Z danych!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-cattle",
   "metadata": {},
   "source": [
    "W pakiecie pgmpy zaimplementowane są następujące algorytmy do uczenia struktury Sieci Bayesowskich:\n",
    "1. Struktura drzewiasta:\n",
    "   1. Tree-augmented Naive Bayes - [pgmpy.estimators.TreeSearch](http://pgmpy.org/estimators.html#pgmpy.estimators.TreeSearch)\n",
    "   2. Chow-Liu algorithm - [pgmpy.estimators.TreeSearch](http://pgmpy.org/estimators.html#pgmpy.estimators.TreeSearch)\n",
    "2. Struktura DAG:\n",
    "   * score-based:\n",
    "       1. Przegląd zupełny - [pgmpy.estimators.ExhaustiveSearch](http://pgmpy.org/estimators.html#pgmpy.estimators.ExhaustiveSearch)\n",
    "       2. Tabu Search - [pgmpy.estimators.HillClimbSearch](http://pgmpy.org/estimators.html#pgmpy.estimators.HillClimbSearch)\n",
    "   * constraint-based:\n",
    "       3. Algorytm PC z ograniczeniami - [pgmpy.estimators.PC](http://pgmpy.org/estimators.html#)\n",
    "   * podejście hybrydowe:\n",
    "       4. MMHC (Max-Min [Local-to-Global Learner with] Hill Climbing) - [pgmpy.estimators.MmhcEstimator](http://pgmpy.org/estimators.html#pgmpy.estimators.MmhcEstimator)\n",
    "   \n",
    "W przypadku `ExhaustiveSearch` oraz `HillClimbSearch` musimy określić funkcję oceniającą dopasowanie struktury do danych - `scoring_method`. W pakiecie zaimplementowane są następujące funkcje:\n",
    "1. BDeu Score - [pgmpy.estimators.BDeuScore](http://pgmpy.org/estimators.html#pgmpy.estimators.BDeuScore)\n",
    "2. Bic Score - [pgmpy.estimators.BicScore](http://pgmpy.org/estimators.html#pgmpy.estimators.BicScore)\n",
    "3. K2 Score - [pgmpy.estimators.K2Score](http://pgmpy.org/estimators.html#pgmpy.estimators.K2Score)\n",
    "\n",
    "Ponadto istnieje możliwość implementacji własnych metod dziedziczących po klasie [pgmpy.estimators.StructureScore](http://pgmpy.org/estimators.html#pgmpy.estimators.StructureScore)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-greeting",
   "metadata": {},
   "source": [
    "#### Ewaluacja struktury\n",
    "Posiadając rzeczywistą strukturę referncyjną możemy obliczyć jakość wyuczonego modelu jako miara F1 namaceirzy sąsiedztwa grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "def get_f1_score(estimated_model, true_model):\n",
    "    nodes = estimated_model.nodes()\n",
    "    est_adj = nx.to_numpy_matrix(estimated_model.to_undirected(), nodelist=nodes, weight=None)\n",
    "    true_adj = nx.to_numpy_matrix(true_model.to_undirected(), nodelist=nodes, weight=None)\n",
    "    \n",
    "    return f1_score(np.ravel(true_adj), np.ravel(est_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-johnson",
   "metadata": {},
   "source": [
    "#### Przegląd zupełny\n",
    "Dla zbiorów danych powyżej 6 zmiennych będzie trwać bardzo długo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import ExhaustiveSearch, K2Score\n",
    "get_f1_score(\n",
    "    ExhaustiveSearch(df, scoring_method=K2Score(df)).estimate(),\n",
    "    bn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-custom",
   "metadata": {},
   "source": [
    "#### Tabu Search\n",
    "\n",
    "Opis parametrów metody `estimate`:\n",
    ">        scoring_method: str or StructureScore instance\n",
    "            The score to be optimized during structure estimation.  Supported\n",
    "            structure scores: k2score, bdeuscore, bicscore. Also accepts a\n",
    "            custom score but it should be an instance of `StructureScore`.\n",
    ">        start_dag: DAG instance\n",
    "            The starting point for the local search. By default a completely\n",
    "            disconnected network is used.\n",
    ">        fixed_edges: iterable\n",
    "            A list of edges that will always be there in the final learned model.\n",
    "            The algorithm will add these edges at the start of the algorithm and\n",
    "            will never change it.\n",
    ">        tabu_length: int\n",
    "            If provided, the last `tabu_length` graph modifications cannot be reversed\n",
    "            during the search procedure. This serves to enforce a wider exploration\n",
    "            of the search space. Default value: 100.\n",
    ">        max_indegree: int or None\n",
    "            If provided and unequal None, the procedure only searches among models\n",
    "            where all nodes have at most `max_indegree` parents. Defaults to None.\n",
    ">        black_list: list or None\n",
    "            If a list of edges is provided as `black_list`, they are excluded from the search\n",
    "            and the resulting model will not contain any of those edges. Default: None\n",
    ">        white_list: list or None\n",
    "            If a list of edges is provided as `white_list`, the search is limited to those\n",
    "            edges. The resulting model will then only contain edges that are in `white_list`.\n",
    "            Default: None\n",
    ">        epsilon: float (default: 1e-4)\n",
    "            Defines the exit condition. If the improvement in score is less than `epsilon`,\n",
    "            the learned model is returned.\n",
    ">        max_iter: int (default: 1e6)\n",
    "            The maximum number of iterations allowed. Returns the learned model when the\n",
    "            number of iterations is greater than `max_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.base import DAG\n",
    "\n",
    "start_dag = DAG()\n",
    "start_dag.add_nodes_from(bn)\n",
    "start_dag.add_edge(sat, letter)\n",
    "get_f1_score(\n",
    "    HillClimbSearch(df).estimate(\n",
    "        scoring_method=K2Score(df),\n",
    "        start_dag=start_dag,\n",
    "    ),\n",
    "    bn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-appointment",
   "metadata": {},
   "source": [
    "#### Algorytm PC\n",
    "Referencje:\n",
    "1. Spirtes, P., Glymour, C., & Scheines, R. (2000). Causation, prediction, and search, 2nd edition. In Journal of Marketing Research (Vol. 39, Issue 1). p.84 Sec. 5.4.2 The PC Algorithm\n",
    "2. Colombo, Diego, and Marloes H. Maathuis. \"Order-independent constraint-based causal structure learning.\" J. Mach. Learn. Res. 15.1 (2014): 3741-3782.\n",
    "3. Le, Thuc Duy, et al. \"A fast PC algorithm for high dimensional causal discovery with multi-core PCs.\" IEEE/ACM transactions on computational biology and bioinformatics 16.5 (2016): 1483-1495.\n",
    "4. Neapolitan, Richard E. Learning bayesian networks. Vol. 38. Upper Saddle River, NJ: Pearson Prentice Hall, 2004. p.550 Sec. 10.1.2 Algorithms for Determining DAG patterns Algorithm 10.2\n",
    "\n",
    "Metoda ta buduje DAG na podstawie zbioru niezależności warunkowych pomiędzy zmiennymi. Są one identyfikowane za pomocą testów statystycznych. Alternatywnie użytkownik może ręcznie podać zbiór niezależności.\n",
    "\n",
    "W ogólności metoda posiada trzy kroki:\n",
    "1. Identyfikacja niezależności\n",
    "2. Budowanie *szkieletu* - grafu z nieskierowanymi krawędziami\n",
    "3. Ustalenie orientacji krawędzi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-stomach",
   "metadata": {},
   "source": [
    "##### Testy na warunkową niezależność - [Conditional Independence Tests for PC algorithm](http://pgmpy.org/citests.html#module-pgmpy.estimators.CITests)\n",
    "\n",
    "We wszystkich testach hipoteza zerowa to $$X \\perp Y | Z$$\n",
    "\n",
    "Obecnie dostępne są następujące testy:\n",
    "\n",
    "- `chi_square`\n",
    "- `cressie_read`\n",
    "- `freeman_tuckey`\n",
    "- `g_sq`\n",
    "- `independence_match`\n",
    "- `log_likelihood`\n",
    "- `modified_log_likelihood`\n",
    "- `neyman`\n",
    "- `pearsonr`\n",
    "- `power_divergence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators.CITests import chi_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(\n",
    "    ('test_statistics', 'degrees-of-freedom', 'p-value'),\n",
    "    chi_square(X=letter, Y=intelligence, Z=[grade], data=df, boolean=False)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square(X=letter, Y=intelligence, Z=[grade], data=df, boolean=True, significance_level=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-squad",
   "metadata": {},
   "source": [
    "Za pomocą metody `build_skeleton` z klasy `PC` możemy wykonać odpowiedni zestaw testów i zbudować szkielet modelu. Klasa `PC` posiada następujące parametry:\n",
    "- `data` - zbiór danych\n",
    "- `independencies=None` - zbiór ręcznie zdefiniowanych warunkowych niezależności\n",
    "\n",
    "Metoda `build_skeleton` posiada następujące parametry:\n",
    "- `ci_test=\"chi_square\"` - rodzaj testu w postaci `str` (\"chi_square\", \"pearsonr\" bądź \"independence_match\") albo funkcji\n",
    "- `max_cond_vars=5` - maksymalny rozmiar zbioru zmiennych warunkująych Z\n",
    "- `significance_level=0.01` - poziom istotności dla testów\n",
    "- `variant=\"stable\"` - wariant algorytmu (\"orig\", \"stable\", \"parallel\")\n",
    "- `n_jobs=-1` - liczba wątków dla wariantu \"parallel\"\n",
    "- `show_progress=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_est = PC(data=df)\n",
    "skeleton, separating_sets = pc_est.build_skeleton(variant='parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "pos=graphviz_layout(skeleton, prog='dot')\n",
    "nx.draw(\n",
    "    skeleton,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color='white',\n",
    "    edgecolors='black',\n",
    "    node_size=5000,\n",
    "    arrowsize=10,\n",
    ")\n",
    "plt.xlim(min(list(map(lambda v: v[0], pos.values())))-15, max(list(map(lambda v: v[0], pos.values())))+15)\n",
    "plt.ylim(min(list(map(lambda v: v[1], pos.values())))-15, max(list(map(lambda v: v[1], pos.values())))+15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-point",
   "metadata": {},
   "source": [
    "`separating_sets` to słownik zbiorów separujących dla każdej z nieistniejących krawędzi. Na jego podstawie ustalony będzie kierunek krawędzi.\n",
    "\n",
    "Jeżeli zbiór separujący jest pusty, to zmienne są niezależne - a nie niezależne warunkowo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "separating_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-zealand",
   "metadata": {},
   "source": [
    "Kolejny krok to tranformacja szkieletu w częściowo skierowany acykliczny graf - PDAG. Partially Directed Acyclic Graphs stanowią klasy równoważności dla DAGów względem `separating_sets` na szkielecie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdag = pc_est.skeleton_to_pdag(skeleton, separating_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "pos=graphviz_layout(pdag, prog='dot')\n",
    "nx.draw(\n",
    "    pdag,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color='white',\n",
    "    edgecolors='black',\n",
    "    node_size=5000,\n",
    "    arrowsize=20,\n",
    ")\n",
    "plt.xlim(min(list(map(lambda v: v[0], pos.values())))-15, max(list(map(lambda v: v[0], pos.values())))+15)\n",
    "plt.ylim(min(list(map(lambda v: v[1], pos.values())))-15, max(list(map(lambda v: v[1], pos.values())))+15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-mainland",
   "metadata": {},
   "source": [
    "Ponieważ PDAG ustanawia klasę równoważności, to za finalny model możemy wybrać jakikolwiek DAG bazujący na powyższym PDAG. Służy do tego metoda `to_dag()`. Posiada ona argument `required_edges`, za pomocą którego możemy określić, które krawędzie muszą pojawić się w wyjściowym grafie. Taka operacje ma oczywiście wyłącznie sens dla krawędzi, które występują w obu stronach w PDAG.\n",
    "\n",
    "UWAGA: Okazuje się, że w obecnej wersji biblioteki argument `required_edges` nie jest wykorzystany!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "pc_learned_model = pdag.to_dag()\n",
    "\n",
    "pos=graphviz_layout(pc_learned_model, prog='dot')\n",
    "nx.draw(\n",
    "    pc_learned_model,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color='white',\n",
    "    edgecolors='black',\n",
    "    node_size=5000,\n",
    "    arrowsize=20,\n",
    ")\n",
    "plt.xlim(min(list(map(lambda v: v[0], pos.values())))-15, max(list(map(lambda v: v[0], pos.values())))+15)\n",
    "plt.ylim(min(list(map(lambda v: v[1], pos.values())))-25, max(list(map(lambda v: v[1], pos.values())))+25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-establishment",
   "metadata": {},
   "source": [
    "Widzimy, że domyślny DAG (bez wyspecyfikowania krawędzi do zachowania) nie zgadza się z oryginalnym modelem - występuje krawędź SAT -> Intelligence zamiast Intelligence -> SAT.\n",
    "\n",
    "Ta sytuacja pokazuje, że na ostatnim kroku metody PC powinniśmy przeanalizować otrzymany PDAG i w miarę możliwości dokonać ręcznego ukierunkowania krawędzi.\n",
    "\n",
    "Gdyby argument `required_edges` był wykorzystywany, dodalibyśmy tutaj krawędź Intelligence -> SAT jako wymaganą."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-legislation",
   "metadata": {},
   "source": [
    "Powyższa procedura składa sie z kroków, które zostały zebrane jako metoda `estimate` klasy `PC`. Ma ona sygnaturę tożsamą z `build_skeleton` z dodatkowym argumentem `return_type`, który przyjmuje wartości `\"dag\"` (domyślnie) bądź `\"pdag\"` i specyfikuje jakiego typu modelu oczekujemy na wyjściu metody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_learned_model_auto = pc_est.estimate(variant='parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "pos=graphviz_layout(pc_learned_model_auto, prog='dot')\n",
    "nx.draw(\n",
    "    pc_learned_model_auto,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color='white',\n",
    "    edgecolors='black',\n",
    "    node_size=5000,\n",
    "    arrowsize=20,\n",
    ")\n",
    "plt.xlim(min(list(map(lambda v: v[0], pos.values())))-15, max(list(map(lambda v: v[0], pos.values())))+15)\n",
    "plt.ylim(min(list(map(lambda v: v[1], pos.values())))-25, max(list(map(lambda v: v[1], pos.values())))+25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-forest",
   "metadata": {},
   "source": [
    "Na tak otrzymanym modelu należy dokonać estymacji warunkowych rozkładów prawdopobieństwa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-judgment",
   "metadata": {},
   "source": [
    "#### Podejście hybrydowe MMHC\n",
    "Tsamardinos, I., Brown, L. E., & Aliferis, C. F. (2006). The max-min hill-climbing Bayesian network structure learning algorithm. Machine Learning, 65(1), 31–78. https://doi.org/10.1007/s10994-006-6889-7\n",
    "\n",
    "Metoda polega na:\n",
    "1. Identyfikacji nieskierowanego szkieletu\n",
    "\n",
    "   W tym celu wykorzystana jest technika podobna jak PC (opiera się na testach statystycznych na warunkową niezależność). Autorzy twierdzą, że ich podejście działa efektywniej niż PC, ponieważ wymaga wykonania mniejszej ilości testów - jest to korzystne także ze względu na wielokrotne testowanie (ang. *Multiple comparisons problem*).\n",
    "   \n",
    "2. Zorientowania krawędzi z wykorzystaniem metody score-based\n",
    "\n",
    "   Krawędzie ze szkieletu (czyli skierowane w obie strony) są wykorzystane jako white-list dla metody Tabu Search.\n",
    "\n",
    "Analogiczną metodę można samemu stworzyć wykorzystując pierwszą część algorytmu PC oraz dowolną metodę score-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import MmhcEstimator, BDeuScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmhc_est = MmhcEstimator(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmhc_learned_model = mmhc_est.estimate(scoring_method=BDeuScore(data=df), tabu_length=100, significance_level=0.01)\n",
    "\n",
    "# ręczna implementacja dwóch kroków\n",
    "# mmpc_skleton = mmhc_est.mmpc(significance_level=0.01)\n",
    "# hc = HillClimbSearch(data=df, scoring_method=BDeuScore(data=df))\n",
    "# mmhc_learned_model = hc.estimate(tabu_length=100, white_list=mmpc_skleton .to_directed().edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-payment",
   "metadata": {},
   "source": [
    "Metoda nie działa w obecnej wersji biblioteki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmhc_learned_model.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-billion",
   "metadata": {},
   "source": [
    "# Wnioskowanie przyczynowe (ang. Causal inference)\n",
    "Wnioskowanie przyczynowe jest potrzebne ponieważ **korelacja to nie przyczynowość** i samo podejście probabilistyczne nie zawsze jest wystarczające.\n",
    "\n",
    "Podstawowe dwa modele wnioskowania przyczynowego to:\n",
    "- model równań strukturalnych\n",
    "- model Pearla (bazuje na Sieciach Bayesowskich)\n",
    "\n",
    "Oba zaimplementowane są bibliotece pgmpy - [pgmpy.inference.CausalInference.CausalInference](http://pgmpy.org/inference.html#pgmpy.inference.CausalInference.CausalInference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
