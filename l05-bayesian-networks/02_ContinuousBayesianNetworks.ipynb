{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "material-champagne",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-arrangement",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-chess",
   "metadata": {},
   "source": [
    "W poprzednim zeszycie poznaliśmy metody dla Sieci Bayesowskich, gdzie wszystkie zmienne były dyskretne. Każdy z rozkładów warunkowych był zapisany w formie tabeli z wykorzystaniem klasy `TabularCPD`, która dziedzy po klasie `DiscreteFactor`.\n",
    "\n",
    "Kolejną klasą dziedziczącą po `DiscreteFactor` jest [`JointProbabilityDistribution`](http://pgmpy.org/factors.html#pgmpy.factors.discrete.JointProbabilityDistribution.JointProbabilityDistribution), która jak sama nazwa wskazuje, służy do reprezentowania łącznych rozkładów prawdopobieństwa dla zmiennych losowych dyskretnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.factors.discrete.JointProbabilityDistribution import JointProbabilityDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-latex",
   "metadata": {},
   "source": [
    "Funkcja `__init__` przyjmuje 3 argumenty:\n",
    "- `variables` - lista zmiennych na których określony jest rozkład\n",
    "- `cardinality` - lista rozmiarów nośnika dla każdej zmiennej\n",
    "- `values` - lista wartości prawdopobieństwa dla każdego z możliwych stanów wektora losowego\n",
    "\n",
    "Czyli dla zmiennych $x1$, $x2$ i $x3$ o następującym rozkładzie łącznym:\n",
    "> \n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        |  x1 |  x2 |  x3 |    P(x1, x2, x2)                |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_0| x2_0| x3_0|    P(x1_0, x2_0, x3_0) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_1| x2_0| x3_0|    P(x1_1, x2_0, x3_0) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_0| x2_1| x3_0|    P(x1_0, x2_1, x3_0) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_1| x2_1| x3_0|    P(x1_1, x2_1, x3_0) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_0| x2_0| x3_1|    P(x1_0, x2_0, x3_1) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_1| x2_0| x3_1|    P(x1_1, x2_0, x3_1) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_0| x2_1| x3_1|    P(x1_0, x2_1, x3_1) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        | x1_1| x2_1| x3_1|    P(x1_1, x2_1, x3_1) = 0.1250 |\n",
    "        +-----+-----+-----+---------------------------------+\n",
    "        \n",
    "obiekt rozkładu łącznego zainicjujemy w następujący sposób"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpd = JointProbabilityDistribution(\n",
    "    ['x1', 'x2', 'x3'],\n",
    "    [2, 2, 2],\n",
    "    np.ones(8)/8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-feeding",
   "metadata": {},
   "source": [
    "Możemy teraz na przykład sprawdzić niezależnośc warunkową $x1$ od $x2$ pod warunkiem $x3=0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpd.check_independence(event1=['x1'], event2=['x2'], event3=[('x3', 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-bride",
   "metadata": {},
   "source": [
    "Albo zwykłą niezależność $x1$ od $(x2, x3)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpd.check_independence(event1=['x1'], event2=['x2', 'x3'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-nylon",
   "metadata": {},
   "source": [
    "I wiele innych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-escape",
   "metadata": {},
   "source": [
    "# Zmienne ciągłe\n",
    "\n",
    "Ograniczanie modelowania tylko do zmiennych dyskretnych jest niepraktyczne jednak mimo to większość pakietów open-source nie posiada wsparcia dla ciągłych zmiennych losowych. Na tym tle wyróżnia się pgmpy, które posiada pewne możliwości w tym zakresie.\n",
    "\n",
    "Klasą pozwalającą na implementację ciągłych rozkładów łącznych jest [pgmpy.factors.continuous.ContinuousFactor.ContinuousFactor](http://pgmpy.org/factors.html#pgmpy.factors.continuous.ContinuousFactor.ContinuousFactor)\n",
    "\n",
    "Jest to klasa za pomocą której możemy zdefiniować dowolony ciągły rozkład łączny. Funkcja `__init__` przyjmuje następujące argumenty:\n",
    "   - `variables` - lista nazw zmiennych\n",
    "   - `pdf` - funkcja gęstości rozkładu łącznego; musi posiadać tyle argumentów, ile zmiennych podaliśmy w `variables`\n",
    "   \n",
    "Klasa posiada metody umożliwiające dyskretyzację rozkładu ciągłego, tworzenie rozkładów warunkowych poprzez dzielenie z rozkładami brzegowymi, marginalziację zmiennych i wiele innych operacji potrzebnych we wnioskowaniu.\n",
    "\n",
    "Wnioskowanie z wykorzystaniem rozkładów z tej klasy staje się obliczeniowo kosztowne dla większych modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import beta\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "def drichlet_pdf(x, y):\n",
    "    if x+y==1.0:\n",
    "        return dirichlet.pdf([x, y], [2, 2])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "from pgmpy.factors.continuous import ContinuousFactor\n",
    "dirichlet_factor = ContinuousFactor(['x', 'y'], drichlet_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf(0.3,0.7)\n",
    "dirichlet_factor.pdf(0.3,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-income",
   "metadata": {},
   "source": [
    "Zmienne ciągłe są w ogólności problematyczne ze względu na odmienność charakteru operacji, które na nich przeprowadzamy. Marginalizacja, warunkowanie, rozkłady łączne, a w konsekwencji Variable Elimination, Belief Propagation oraz inne metody wnioskowania znacznie się komplikują obliczeniowo. Jak zwykle w takich sytuacjach wyjątkiem jest **wielowymiarowy rozkład normalny**, dla którego jesteśmy w stanie wyprowadzić wszystkie operacje w zamkniętej postaci.\n",
    "\n",
    "W tym miejscu wprowadzamy tzw. **Canonical Form Representation**:\n",
    "$$\\mathcal{C}(\\pmb{x}; K, \\pmb{h}, g) = \\exp \\left( - \\frac{1}{2} \\pmb{x} ^\\intercal K \\pmb{x} + \\pmb{h}^\\intercal \\pmb{x} + g \\right),$$\n",
    "dla wektora losowego $\\pmb{x}$ o rozkładzie $\\mathcal{N}(\\pmb{\\mu}, \\Sigma)$, gdzie\n",
    "$$\n",
    "\\begin{gather}\n",
    "K = \\Sigma ^{-1} \\\\\n",
    "\\pmb{h} = \\Sigma ^{-1} \\pmb{\\mu} \\\\ \n",
    "g = - \\frac{1}{2}\\pmb{\\mu}^\\intercal \\Sigma^{-1} \\pmb{\\mu} - \\log \\left((2 \\pi)^{n/2}|\\Sigma|^{1/2}\\right)\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Taka parametryzacja umożliwia łatwe wykonywanie operacji potrzebnych przy wnioskowaniu. Dokładne opisy oraz przykłady, jak i omówienie całego zagadnienia stosowania zmiennych ciągłych w Probabilistycznych Modelach Grafowych odsyłam do:\n",
    "*Probabilistic Graphical Models, Principles and Techniques, Daphne Koller and Nir Friedman, p. 605 Chapter 14. Inference in Hybrid Networks*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-comedy",
   "metadata": {},
   "source": [
    "## Gaussian Bayesian Networks\n",
    "Gaussian Bayesian Networks to model, który składa się wyłącznie z ciągłych zmiennych o rozkładzie normalnym, a wszystkie rozkłady warunkowe są liniowo zależne - nazywamy je linear Gaussian model. Można pokazać, że taki model ustanawia rozkład łączny będący wielowymiarowym rozkładem normalnym.\n",
    "\n",
    "Niech $Y$ będzie ciągłą zmienną losową z ciągłymi rodzicami $X_1, \\ldots, X_k$. Mówimy, że $Y$ ma *linear Gaussian model* jeżeli istnieją parametry $\\beta_0, \\ldots, \\beta_k$ i $\\sigma^2$ takie, że\n",
    "$$p(Y|x_1, \\ldots, x_k) = \\mathcal{N}(Y|\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k, \\sigma^2)$$\n",
    "\n",
    "Dla tej klasy modeli można wyprowadzić Variable Elimination oraz Belief Propagation.\n",
    "\n",
    "Literatura:\n",
    "- *Probabilistic Graphical Models, Principles and Techniques, Daphne Koller and Nir Friedman, p. 247 Chapter 7. Gaussian Network Models*\n",
    "- *Probabilistic Graphical Models, Principles and Techniques, Daphne Koller and Nir Friedman, p. 608 Chapter 14.2 Variable Elimination in Gaussian Networks*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-hungary",
   "metadata": {},
   "source": [
    "W pakiecie pgmpy możemy budować Gaussian Bayesian Networks wykorzystując klasy:\n",
    "- do reprezentowania rozkładów - [pgmpy.factors.continuous.LinearGaussianCPD.LinearGaussianCPD](http://pgmpy.org/factors.html#pgmpy.factors.continuous.LinearGaussianCPD.LinearGaussianCPD)\n",
    "\n",
    "   Jest to klasa, za pomocą której tworzymy linear Gaussian model dla zmiennej $Y$ zależnej od wektora losowego $[X_1, \\ldots, X_k]$. Funkcja `__init__` przyjmuje następujące argumenty:\n",
    "   - `variable` - nazwa zmiennej\n",
    "   - `evidence_mean` - lista $k+1$ wartości parametrów modelu $\\pmb{\\beta}$ z wyrazem wolnym na pierwszej pozycji\n",
    "   - `evidence_variance`- wariancja $Y$, czyli $\\sigma^2$\n",
    "   - `evidence` - lista nazw zmiennych w wektorze losowym $[X_1, \\ldots, X_k]$\n",
    "   - `beta=None` - argument, który nic nie robi \n",
    "   \n",
    "   Istotnym faktem jest, że klasa posiada metodę `fit`, która zwraca estymator ML dla parametrów modelu na podstawie danych zawierających realizacje $[Y, X_1, \\ldots, X_k]$.\n",
    "   \n",
    "- do zbudowania modelu - `pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork` o interfejsie analogicznym do `BayesianModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import pandas as pd\n",
    "\n",
    "real_betas = np.array([1, 0.3, -0.4, 0.7])\n",
    "real_sigma2 = 0.6\n",
    "parents_means = np.array([1, 5, -6])\n",
    "parents_cov = np.array([\n",
    "    [5, 0, 0],\n",
    "    [0, 2, 0],\n",
    "    [0, 0, 0.04]\n",
    "])\n",
    "\n",
    "def get_cov(beta_coeffs, cov, i):\n",
    "    return np.sum(cov[i, :] * beta_coeffs)\n",
    "\n",
    "gbn_generator = multivariate_normal(\n",
    "    mean=[*parents_means, real_betas[0]+np.sum(real_betas[1:]*parents_means)],\n",
    "    cov=np.array([\n",
    "        [*parents_cov[0, :], get_cov(real_betas[1:], parents_cov, 0)],\n",
    "        [*parents_cov[1, :], get_cov(real_betas[1:], parents_cov, 1)],\n",
    "        [*parents_cov[2, :], get_cov(real_betas[1:], parents_cov, 2)],\n",
    "        [\n",
    "            get_cov(real_betas[1:], parents_cov, 0),\n",
    "            get_cov(real_betas[1:], parents_cov, 1),\n",
    "            get_cov(real_betas[1:], parents_cov, 2),\n",
    "            real_sigma2 + real_betas[1:]@parents_cov@real_betas[1:].transpose()\n",
    "            \n",
    "        ]\n",
    "    ])\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    gbn_generator.rvs(size=5000),\n",
    "    columns=['x1', 'x2', 'x3', '(Y|X)']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel, LinearGaussianBayesianNetwork\n",
    "from pgmpy.factors.continuous import LinearGaussianCPD\n",
    "\n",
    "gnb = LinearGaussianBayesianNetwork([\n",
    "    ('x1', 'y'),\n",
    "    ('x2', 'y'),\n",
    "    ('x3', 'y')\n",
    "])\n",
    "\n",
    "betas, sigma = LinearGaussianCPD(\n",
    "        variable='y',\n",
    "        evidence_mean=None,\n",
    "        evidence_variance=None,\n",
    "        evidence=['x1', 'x2', 'x3']\n",
    ").fit(data=df, states=['x1', 'x2', 'x3', '(Y|X)'], estimator='MLE')\n",
    "\n",
    "print(betas)\n",
    "print(sigma**2)\n",
    "\n",
    "gnb.add_cpds(\n",
    "    LinearGaussianCPD(\n",
    "        variable='x1',\n",
    "        evidence_mean=[parents_means[0]],\n",
    "        evidence_variance=parents_cov[0,0],\n",
    "    ),\n",
    "    LinearGaussianCPD(\n",
    "        variable='x2',\n",
    "        evidence_mean=[parents_means[1]],\n",
    "        evidence_variance=parents_cov[1,1],\n",
    "    ),\n",
    "    LinearGaussianCPD(\n",
    "        variable='x3',\n",
    "        evidence_mean=[parents_means[2]],\n",
    "        evidence_variance=parents_cov[2,2],\n",
    "    ),\n",
    "    LinearGaussianCPD(\n",
    "        variable='y',\n",
    "        evidence_mean=betas,\n",
    "        evidence_variance=sigma,\n",
    "        evidence=['x1', 'x2', 'x3']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-bullet",
   "metadata": {},
   "source": [
    "Niestety wnioskowanie dla ciągłych modeli nie jest jeszcze gotowe. Ale prawdopodobnie:\n",
    "    \n",
    "- łatwo naprawić\n",
    "- ktoś już to zrobił - biblioteka ma obecnie 567 forków na [github.com/pgmpy/pgmpy](https://github.com/pgmpy/pgmpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve = VariableElimination(gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-script",
   "metadata": {},
   "source": [
    "# Dyskretyzacja ciągłych rozkładów\n",
    "Alternatywą dla reprezentacji ciągłych zmiennych jest ich dyskretyzacja. To rozwiązanie nie sprawdzi się w każdej sytuacji, ale umożliwia pracę z (aproksymacjami) dowolnymi rozkładami ciągłymi w Sieciach Bayesowskich.\n",
    "\n",
    "Przykład zastosowania dyskretyzacji znajduje się w zeszycie **A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-lotus",
   "metadata": {},
   "source": [
    "Dyskretyzację można wykonać \"manualnie\" albo wykorzystując funkcjonalność biblioteki pgmpy. Klasą bazową dla dyskretyzatorów jest [pgmpy.factors.continuous.discretize.BaseDiscretizer](http://pgmpy.org/factors.html#pgmpy.factors.continuous.discretize.BaseDiscretizer). Obecnie dostępne są dwa algorytmy:\n",
    "- [RoundingDiscretizer](http://pgmpy.org/factors.html#pgmpy.factors.continuous.discretize.RoundingDiscretizer)\n",
    "- [UnbiasedDiscretizer](http://pgmpy.org/factors.html#pgmpy.factors.continuous.discretize.UnbiasedDiscretizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.factors.continuous.discretize import RoundingDiscretizer, UnbiasedDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_t\n",
    "\n",
    "def multi_t_pdf(x, y):\n",
    "    return multivariate_t([1.0, -0.5], [[2.1, 0.3], [0.3, 1.5]], df=2).pdf([x, y])\n",
    "\n",
    "t_factor = ContinuousFactor(['x', 'y'], multi_t_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_factor.pdf(1.4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_factor = t_factor.marginalize(['x'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(\n",
    "    np.linspace(-10, 10, num=100),\n",
    "    list(map(y_t_factor.pdf, np.linspace(-10, 10, num=100).tolist()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_factor.discretize(\n",
    "    RoundingDiscretizer,\n",
    "    low=-10,\n",
    "    high=10,\n",
    "    cardinality=3,\n",
    "    cdf_opts={ # default opts\n",
    "        'epsabs': 1.49e-05,\n",
    "        'epsrel': 1.49e-05,\n",
    "        'limit': 30,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_factor.discretize(\n",
    "    UnbiasedDiscretizer,\n",
    "    low=-10,\n",
    "    high=10,\n",
    "    cardinality=3,\n",
    "    cdf_opts={ # non-default opts\n",
    "        'epsabs': 1.49e-03,\n",
    "        'epsrel': 1.49e-03,\n",
    "        'limit': 15,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default opts\n",
    "print('cdf(-10)', y_t_factor.cdf(-10))\n",
    "print('cdf(0)', y_t_factor.cdf(0))\n",
    "print('cdf(10)', y_t_factor.cdf(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-delay",
   "metadata": {},
   "source": [
    "Analogiczną procedurę można wykonać dla zmiennej `\"x\"` i utworzyć dyskretny rozkład łączny za pomocą `JointProbabilityDistribution`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
