{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Weronika Pawlak\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naiwny Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Naiwnego Bayesa jest jednym z najprostszych modeli grafowych. Zakłada on, że wszystkie obserwowane zmienne $X_1, X_2, \\ldots, X_N$ są warunkowo niezależne względem zmiennej $Y$ oraz, że jedyna zależność istnieje między zmienną $Y$ a zmiennymi $\\mathbf{X}$ (zobacz rysunek). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "    \n",
    "g = nx.DiGraph()\n",
    "g.add_edges_from([(\"Y\", \"X_1\"), (\"Y\", \"X_2\"), (\"Y\", \"$X_{N-1}$\"), (\"Y\", \"$X_N$\")])\n",
    "\n",
    "nx.draw(\n",
    "    g, \n",
    "    with_labels=True, \n",
    "    node_color=[\"gray\" if \"X\" in v else \"white\" for v in g.nodes()],\n",
    "    pos={\"Y\": (0, 0), \"X_1\": (-2, -1), \"X_2\": (-1, -1), \"$X_{N-1}$\": (1, -1), \"$X_N$\": (2, -1)},\n",
    "    edgecolors=\"black\",\n",
    "    node_size=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiwny klasyfikator Bayesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszym celem będzie rozwiązać zadanie klasyfikacji, gdzie klasa będzie reprezentowana przez zmienną $Y$ (zakładamy, że istnieje $K$ klas), natomiast atrybuty opisujące dane instancje to $X_1, X_2, \\ldots, X_N$ (wartości te mogą być zarówno ciągłe, jak i dyskretne). \n",
    "\n",
    "Dla konkretnej instancji opisanej $x_1, x_2, \\ldots, x_N$ poszukujemy jej rzeczywistej klasy $\\hat y$, którą uzyskujemy maksymalizując prawdopodobieństwo warunkowe klasy $y_k$ pod warunkiem danych $x_1, x_2, \\ldots, x_N$:\n",
    "\n",
    "$$\\tag{1}\\hat{y} = \\operatorname*{argmax}_{k \\in \\{1, 2, \\ldots, K\\}} \\mathbb{P}(y_k | x_1, x_2, \\ldots, x_N)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując regułę Bayesa możemy to prawdopodobieństwo rozpisać jako:\n",
    "\n",
    "$$\\mathbb{P}(y_k|x_1, x_2, \\ldots, x_N) = \\frac{\\mathbb{P}(y_k)\\mathbb{P}(x_1, x_2, \\ldots, x_N | y_k)}{\\mathbb{P}(x_1, x_2, \\ldots, x_N)}$$\n",
    "\n",
    "Licznik tego ułamka możemy zapisać jako prawdopodbieństwo łączne:\n",
    "\n",
    "$$\\tag{2}\\mathbb{P}(y_k)\\mathbb{P}(x_1, x_2, \\ldots, x_N | y_k) = \\mathbb{P}(y_k, x_1, x_2, \\ldots, x_N)$$\n",
    "\n",
    "Dodatkowo możemy pominąć mianownik i zapisać, że prawdopodobieństwo $\\text{(1)}$ jest proporcjonalne do $\\text{(2)}$:\n",
    "\n",
    "$$\\mathbb{P}(y_k|x_1, x_2, \\ldots, x_N) \\propto \\mathbb{P}(y_k, x_1, x_2, \\ldots, x_N)$$\n",
    "\n",
    "Korzystając wielokrotnie z reguły łańcuchowej możemy dokonać faktoryzacji prawdopodobieństwa łącznego:\n",
    "\n",
    "$$\\tag{3}\n",
    "\\begin{align}\n",
    "\\mathbb{P}(y_k, x_1, x_2, \\ldots, x_N) & = \\mathbb{P}(x_1, x_2, \\ldots, x_N, y_k)\\\\\n",
    "& = \\mathbb{P}(x_1 | x_2, \\ldots, x_N, y_k)\\mathbb{P}(x_2, \\ldots, x_N, y_k) \\\\\n",
    "& \\ldots \\\\\n",
    "& = \\mathbb{P}(x_1 | x_2, \\ldots, x_N, y_k)\\mathbb{P}(x_2 | \\ldots, x_N, y_k) \\ldots \\mathbb{P}(x_{N-1}|x_N, y_k) \\mathbb{P}(x_N | y_k)\\mathbb{P}(y_k)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\"Naiwność\" tego modelu zakłada, że zmienne $X_1, \\ldots, X_N$ są niezależne pod warunkiem $Y$, stąd:\n",
    "\n",
    "$$\\tag{4}\\mathbb{P}(x_i | x_{i+1}, x_{i+2}, \\ldots, x_N, y_k) = \\mathbb{P}(x_i|y_k)$$\n",
    "\n",
    "Aplikując $\\text{(4)}$ do $\\text{(3)}$ otrzymujemy:\n",
    "\n",
    "$$\\mathbb{P}(y_k|x_1, x_2, \\ldots, x_N) \\propto \\mathbb{P}(y_k, x_1, x_2, \\ldots, x_N) = \\mathbb{P}(y_k)\\mathbb{P}(x_1|y_k)\\mathbb{P}(x_2|y_k)\\ldots\\mathbb{P}(x_N|y_k) = \\mathbb{P}(y_k)\\prod_{i=1}^{N}\\mathbb{P}(x_i|y_k)$$\n",
    "\n",
    "$$\\mathbb{P}(y_k|x_1, x_2, \\ldots, x_N) \\propto \\mathbb{P}(y_k)\\prod_{i=1}^{N}\\mathbb{P}(x_i|y_k)$$\n",
    "\n",
    "Ostatecznie otrzymujemy:\n",
    "\n",
    "$$\\hat y = \\operatorname*{argmax}_{k \\in \\{1, 2, \\ldots, K\\}} \\mathbb{P}(y_k)\\prod_{i=1}^{N}\\mathbb{P}(x_i|y_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zmienne ciągłe\n",
    "Będziemy się tutaj posługiwać zbiorem danych Iris, który posiada tylko ciągłe atrybuty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full (150, 4) (150,)\n",
      "Train (120, 4) (120,)\n",
      "Test (30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets as sk_ds\n",
    "from sklearn import model_selection as sk_ms\n",
    "\n",
    "\n",
    "def load_iris_dataset():\n",
    "    X, y = sk_ds.load_iris(return_X_y=True)\n",
    "    X = pd.DataFrame(X, columns=[\n",
    "        \"sepal-length\",\n",
    "        \"sepal-width\",\n",
    "        \"petal-length\",\n",
    "        \"petal-width\",\n",
    "    ])\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = sk_ms.train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "    print(\"Full\", X.shape, y.shape)\n",
    "    print(\"Train\", X_tr.shape, y_tr.shape)\n",
    "    print(\"Test\", X_te.shape, y_te.shape)\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"X\": X_tr, \"y\": y_tr},\n",
    "        \"test\": {\"X\": X_te, \"y\": y_te},\n",
    "    }\n",
    "\n",
    "\n",
    "iris = load_iris_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width\n",
       "87            6.3          2.3           4.4          1.3\n",
       "16            5.4          3.9           1.3          0.4\n",
       "123           6.3          2.7           4.9          1.8\n",
       "137           6.4          3.1           5.5          1.8\n",
       "99            5.7          2.8           4.1          1.3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"train\"][\"X\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 2, 2, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 2, 2, 1, 2, 0, 1, 0, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1,\n",
       "       0, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 1, 2, 2, 2, 0, 1, 2,\n",
       "       0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 2, 2, 2, 1,\n",
       "       2, 2, 0, 2, 1, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1,\n",
       "       2, 0, 2, 0, 1, 1, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"train\"][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja w bibliotece `scikit-learn`\n",
    "Załóżmy, że wszystkie zmienne tutaj pochodzą z rozkładu normalnego - użyjemy klasy `GaussianNB` (model naiwnego Bayesa z rozkładami normalnymi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       0.93      0.93      0.93        40\n",
      "           2       0.93      0.93      0.93        40\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.95      0.95      0.95       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics as sk_mtr\n",
    "\n",
    "\n",
    "clf_scikit = GaussianNB()\n",
    "clf_scikit.fit(X=iris[\"train\"][\"X\"], y=iris[\"train\"][\"y\"])\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    print(split)\n",
    "    print(sk_mtr.classification_report(\n",
    "        y_true=iris[split][\"y\"],\n",
    "        y_pred=clf_scikit.predict(X=iris[split][\"X\"]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja w bibliotece `pyro`\n",
    "Poniżej zamieszczono przykładową implementację modelu naiwnego Baysa za pomocą biblioteki Pyro. Nie będziemy wchodzić w szczegóły, ale zachęcamy aby przeanalizować krok po kroku każdą z metod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro import distributions as dist\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class GaussianNBClassifier:\n",
    "    def __init__(self, num_epochs=500, lr=1e-2):\n",
    "        self._num_epochs = num_epochs\n",
    "        self._lr = lr\n",
    "        \n",
    "        self._num_cls = None\n",
    "        \n",
    "        self._c_logits = None        \n",
    "        self._num_probs = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "        svi = pyro.infer.SVI(\n",
    "            model=self._model,\n",
    "            guide=self._guide,\n",
    "            optim=pyro.optim.Adam({'lr': self._lr}),\n",
    "            loss=pyro.infer.Trace_ELBO(),\n",
    "        )\n",
    "\n",
    "        with tqdm(range(self._num_epochs)) as pbar:\n",
    "            for epoch in pbar:\n",
    "                loss = svi.step(X, y)\n",
    "\n",
    "                if epoch % 100 == 0:\n",
    "                    print(f\"Epoch: {epoch} Loss = {loss:.3f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = pyro.infer.Predictive(\n",
    "            model=self._model,\n",
    "            guide=self._guide,\n",
    "            num_samples=1,\n",
    "            return_sites=('logP(c|x)',),\n",
    "        )\n",
    "        log_pcx = pred(X)['logP(c|x)'].detach().squeeze(0).squeeze(0)\n",
    "        y_pred = torch.argmax(log_pcx, dim=-1)\n",
    "        return y_pred\n",
    "    \n",
    "    def _model(self, X, y=None):    \n",
    "        if y is not None:  # training mode\n",
    "            self._num_cls = max(y) + 1\n",
    "            \n",
    "            numerical_cols = X.columns.values\n",
    "                    \n",
    "            self._init_c_logits()\n",
    "            self._init_num_params(X, numerical_cols)\n",
    "            self._observe_numerical_features_given_classes(X, y)\n",
    "\n",
    "        self._observe_classes(X, y)\n",
    "        \n",
    "    def _guide(self, X, y=None):\n",
    "        pass  # This is meant to be an empty function\n",
    "    \n",
    "    def _init_c_logits(self):\n",
    "        self._c_logits = pyro.param(\n",
    "            'c_logits',\n",
    "            torch.ones(self._num_cls).div(self._num_cls),\n",
    "            constraint=constraints.simplex,\n",
    "        )\n",
    "        \n",
    "    def _init_num_params(self, X, numerical_cols):\n",
    "        self._num_probs = {\n",
    "            col: {\n",
    "                'mu': pyro.param(f'{col}_mu', torch.zeros(self._num_cls)),\n",
    "                'sigma': pyro.param(f'{col}_sigma', torch.ones(self._num_cls)),\n",
    "            }\n",
    "            for col in numerical_cols\n",
    "        }\n",
    "        \n",
    "    def _observe_numerical_features_given_classes(self, X, y):\n",
    "        for c in range(self._num_cls):\n",
    "            x_c = X[y==c]\n",
    "            with pyro.plate(f'data-numerical-{c}', x_c.shape[0]):\n",
    "                for nc, v in self._num_probs.items():\n",
    "                    pyro.sample(\n",
    "                        f'P(x_{nc}|c={c})', \n",
    "                        dist.Normal(v['mu'][c], v['sigma'][c]),\n",
    "                        obs=torch.tensor(x_c[nc].values),\n",
    "                    )\n",
    "                    \n",
    "    def _get_log_likelihood(self, X):\n",
    "        log_lk = []\n",
    "        \n",
    "        for c in range(self._num_cls):\n",
    "            lps = []\n",
    "            \n",
    "            lps.extend([\n",
    "                dist.Normal(v['mu'][c], v['sigma'][c]).log_prob(torch.tensor(X[nc].values))\n",
    "                for nc, v in self._num_probs.items()\n",
    "            ])\n",
    "\n",
    "            log_lk.append(torch.stack(lps).sum(dim=0))\n",
    "            \n",
    "        return torch.stack(log_lk).t()\n",
    "    \n",
    "    def _observe_classes(self, X, y):\n",
    "        if y is not None:\n",
    "            y = torch.tensor(y)\n",
    "        \n",
    "        log_lk = self._get_log_likelihood(X)\n",
    "\n",
    "        log_pcx = pyro.deterministic('logP(c|x)', self._c_logits.log() + log_lk)\n",
    "        \n",
    "        with pyro.plate('data-pred', X.shape[0]):    \n",
    "            pyro.sample(\n",
    "                'c',\n",
    "                dist.Categorical(logits=log_pcx),\n",
    "                obs=y,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c19805f97504617a21967cc1418877e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss = 4360.764\n",
      "Epoch: 100 Loss = 1505.592\n",
      "Epoch: 200 Loss = 1056.422\n",
      "Epoch: 300 Loss = 825.529\n",
      "Epoch: 400 Loss = 669.545\n",
      "Epoch: 500 Loss = 570.902\n",
      "Epoch: 600 Loss = 524.511\n",
      "Epoch: 700 Loss = 484.184\n",
      "Epoch: 800 Loss = 443.606\n",
      "Epoch: 900 Loss = 393.908\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       0.90      0.95      0.93        40\n",
      "           2       0.95      0.90      0.92        40\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.95      0.95      0.95       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pyro = GaussianNBClassifier(num_epochs=1000)\n",
    "clf_pyro.fit(X=iris[\"train\"][\"X\"], y=iris[\"train\"][\"y\"])\n",
    "\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    print(split)\n",
    "    print(sk_mtr.classification_report(\n",
    "        y_true=iris[split][\"y\"],\n",
    "        y_pred=clf_pyro.predict(X=iris[split][\"X\"]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja w bibliotece `pgmpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 (0.75 pkt)\n",
    "\n",
    "Zaimplementuj funkcję `discretize_data`, która dokona dyskretyzacji (np. `KBinsDiscretizer`) zmiennych ciągłych w zadanym zbiorze danych. Zmienne kategoryczne/dyskretne nie powinny zostać zmienione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ca6cd2bf6ae0088a0c7a0a3cc2a742",
     "grade": true,
     "grade_id": "discretize-data",
     "locked": false,
     "points": 0.75,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "def discretize_data(dataset: dict, n_bins: int) -> dict:\n",
    "    _dataset = deepcopy(dataset)\n",
    "    \n",
    "    X_train = _dataset[\"train\"][\"X\"]\n",
    "    X_test = _dataset[\"test\"][\"X\"]\n",
    "    \n",
    "    discrete_cols = X_train.select_dtypes('category').columns.values\n",
    "    continuous_cols = [c for c in X_train.columns if c not in discrete_cols]\n",
    "    est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "    X_train[continuous_cols] = est.fit_transform(X_train[continuous_cols])\n",
    "    X_test[continuous_cols] = est.transform(X_test[continuous_cols])\n",
    "    _dataset[\"train\"][\"X\"] = X_train\n",
    "    _dataset[\"test\"][\"X\"] = X_test\n",
    "    # TU WPISZ KOD\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (0.4 pkt)\n",
    "\n",
    "Zaimplementuj funkcję `build_model`, która zbuduje model Naiwnego Bayesa na podstawie obiektu `BayesianModel` (nie wykorzytuj klasy `NaiveBayes` z pgmpy!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc3c2d070fca34c96f6a8fee90a1daf8",
     "grade": true,
     "grade_id": "build-model",
     "locked": false,
     "points": 0.4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "\n",
    "def build_model(dataset: dict) -> BayesianModel:\n",
    "    model = BayesianModel()\n",
    "    for x in list(dataset['train']['X'].columns):\n",
    "        model.add_edge('y', x)\n",
    "    return  model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (0.5 pkt)\n",
    "\n",
    "Zaimplementuj funkcję `fit_model`, która dopasuje parametry modelu Naiwnego Bayesa. Użyj dowolnej metody estymacji (np. Maximum Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0d6f2b245d2ef9edbc0a3dec8479578",
     "grade": true,
     "grade_id": "fit-model",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "def fit_model(model: BayesianModel, training_data: dict) -> BayesianModel:\n",
    "    _dataset = deepcopy(training_data['X'])\n",
    "    _dataset['y'] = training_data['y']\n",
    "    model.fit(_dataset, estimator=MaximumLikelihoodEstimator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4 (0.75 pkt)\n",
    "\n",
    "Zaimplementuj funkcję `predict_pgmpy`, która zwróci predykcje modelu Naiwnego Bayesa dla zadanych danych `X`. Użyj dowolnej metody inferencji (np. Variable Elimination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf83cd2aa629bf9cff640e1a81b62d7b",
     "grade": true,
     "grade_id": "predict-pgmpy",
     "locked": false,
     "points": 0.75,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "def predict_pgmpy(model, X):\n",
    "    ve = VariableElimination(model)\n",
    "    y_pred = []\n",
    "    #print(X)\n",
    "    for idx, row in X.iterrows():\n",
    "        query = ve.map_query(['y'], dict(row),show_progress=False)\n",
    "        y_pred.append(query['y'])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystajmy teraz zaimplementowane funkcje, aby wyuczyć model Naiwnego Bayesa w pgmpy i sprawdźmy jakość działania modelu na zdyskretyzowanych danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       0.88      0.90      0.89        40\n",
      "           2       0.90      0.88      0.89        40\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.93      0.92      0.92       120\n",
      "weighted avg       0.93      0.93      0.92       120\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pgmpy\\factors\\discrete\\DiscreteFactor.py:460: RuntimeWarning: invalid value encountered in true_divide\n",
      "  phi.values = phi.values / phi.values.sum()\n"
     ]
    }
   ],
   "source": [
    "iris_discrete = discretize_data(dataset=iris, n_bins=5)\n",
    "#print(iris_discrete[\"train\"]['y'])\n",
    "clf_pgmpy = build_model(dataset=iris_discrete)\n",
    "clf_pgmpy = fit_model(model=clf_pgmpy, training_data=iris_discrete[\"train\"])\n",
    "\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    print(split)\n",
    "    print(sk_mtr.classification_report(\n",
    "        y_true=iris_discrete[split][\"y\"],\n",
    "        y_pred=predict_pgmpy(model=clf_pgmpy, X=iris_discrete[split][\"X\"]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zmienne ciągłe i dyskretne\n",
    "Wykorzystaj zbiór CMC, aby sprawdzić wszystkie modele na zbiorze z cechami dyskretnymi i ciągłymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cmc(N=-1):\n",
    "    # Source: https://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice\n",
    "    df = pd.read_csv('data/cmc.data', names=[\n",
    "        'age', # numerical\n",
    "        'w-education', # categorical\n",
    "        'h-education',  # categorical\n",
    "        'num-children',  # numerical\n",
    "        'w-religion',  # binary\n",
    "        'w-working',  # binary\n",
    "        'h-occupation',  # categorical\n",
    "        'sol-index',  # categorical\n",
    "        'media-exposure',  # binary\n",
    "        'contraceptive-method-used',  # class\n",
    "    ])\n",
    "\n",
    "    cat_cols = [\n",
    "        'w-education', # categorical\n",
    "        'h-education',  # categorical\n",
    "        'h-occupation',  # categorical\n",
    "        'sol-index',  # categorical\n",
    "    ]\n",
    "    bin_cols = [\n",
    "        'w-religion',  # binary\n",
    "        'w-working',  # binary\n",
    "        'media-exposure',  # binary\n",
    "    ]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df[col] = (df[col] - 1).astype('category')\n",
    "\n",
    "    for col in bin_cols:\n",
    "        df[col] = df[col].astype('category')    \n",
    "\n",
    "    if N != -1:\n",
    "        df = df.sample(\n",
    "            n=N,\n",
    "            weights='contraceptive-method-used',\n",
    "            random_state=2020,\n",
    "        )\n",
    "\n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df['contraceptive-method-used'].values - 1\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = sk_ms.train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "    print('Full', X.shape, y.shape)\n",
    "    print('Train', X_tr.shape, y_tr.shape)\n",
    "    print('Test', X_te.shape, y_te.shape)\n",
    "\n",
    "    return {\n",
    "        'train': {'X': X_tr.reset_index(drop=True), 'y': y_tr},\n",
    "        'test': {'X': X_te.reset_index(drop=True), 'y': y_te},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full (200, 9) (200,)\n",
      "Train (160, 9) (160,)\n",
      "Test (40, 9) (40,)\n"
     ]
    }
   ],
   "source": [
    "cmc = load_cmc(N=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>w-education</th>\n",
       "      <th>h-education</th>\n",
       "      <th>num-children</th>\n",
       "      <th>w-religion</th>\n",
       "      <th>w-working</th>\n",
       "      <th>h-occupation</th>\n",
       "      <th>sol-index</th>\n",
       "      <th>media-exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age w-education h-education  num-children w-religion w-working  \\\n",
       "0   43           3           3             5          0         1   \n",
       "1   37           3           3             1          1         1   \n",
       "2   32           1           2             4          1         1   \n",
       "3   27           2           3             2          1         1   \n",
       "4   32           3           3             2          1         0   \n",
       "\n",
       "  h-occupation sol-index media-exposure  \n",
       "0            0         3              0  \n",
       "1            0         3              0  \n",
       "2            2         1              0  \n",
       "3            0         2              0  \n",
       "4            0         3              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmc[\"train\"][\"X\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2,\n",
       "       1, 2, 2, 1, 2, 0, 2, 2, 0, 0, 2, 1, 0, 0, 0, 1, 2, 2, 2, 0, 1, 2,\n",
       "       0, 2, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 1,\n",
       "       2, 2, 0, 0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 0, 1, 2, 2, 2,\n",
       "       2, 1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0,\n",
       "       2, 0, 2, 1, 1, 0, 2, 1, 1, 0, 2, 0, 1, 2, 2, 1, 0, 2, 2, 0, 2, 1,\n",
       "       2, 2, 2, 0, 0, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 2, 2, 1, 2, 0, 2, 1,\n",
       "       2, 0, 0, 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmc[\"train\"][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja w `pyro`\n",
    "Poprzednio użyta implementacja Naiwnego Bayesa w bibliotece Pyro nie obsługuje zmiennych dyskretnych. Poniżej zamieszczamy implementację obsługująca oba typy zmiennych. Zachęcamy do dokładniejszej analizy kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNBClassifier(GaussianNBClassifier):\n",
    "    def __init__(self, num_epochs=500, lr=1e-2):\n",
    "        super().__init__(num_epochs, lr)\n",
    "        self._cat_probs = None\n",
    "        \n",
    "    # fit() from base class\n",
    "    \n",
    "    # predict() from base class\n",
    "    \n",
    "    def _model(self, X, y=None):  # Override  \n",
    "        if y is not None:  # training mode\n",
    "            self._num_cls = max(y) + 1\n",
    "            \n",
    "            categorical_cols = X.select_dtypes('category').columns.values  # Changed\n",
    "            numerical_cols = [c for c in X.columns if c not in categorical_cols]  # Changed\n",
    "                    \n",
    "            self._init_c_logits()\n",
    "            self._init_num_params(X, numerical_cols)\n",
    "            self._init_cat_params(X, categorical_cols)  # Added \n",
    "            \n",
    "            self._observe_numerical_features_given_classes(X, y)\n",
    "            self._observe_categorical_features_given_classes(X, y)  # Added\n",
    "\n",
    "        self._observe_classes(X, y)\n",
    "        \n",
    "    # _guide() from base class\n",
    "    \n",
    "    # _init_c_logits() from base class\n",
    "        \n",
    "    # _init_num_params() from base class\n",
    "        \n",
    "    def _init_cat_params(self, X, categorical_cols):  # Add\n",
    "        self._cat_probs = {\n",
    "            col: pyro.param(\n",
    "                f'{col}_probs', \n",
    "                torch.ones([self._num_cls, len(X[col].cat.categories)]),\n",
    "                constraint=constraints.positive\n",
    "            )\n",
    "            for col in categorical_cols\n",
    "        }\n",
    "        \n",
    "    # _observe_numerical_features_given_classes from base class\n",
    "    \n",
    "    def _observe_categorical_features_given_classes(self, X, y):  # Add\n",
    "        for c in range(self._num_cls):\n",
    "            x_c = X[y==c]\n",
    "            with pyro.plate(f'data-categorical-{c}', x_c.shape[0]):\n",
    "                for cc, v in self._cat_probs.items():\n",
    "                    pyro.sample(\n",
    "                        f'P(x_{cc}|c={c})',\n",
    "                        dist.Categorical(logits=v[c]),\n",
    "                        obs=torch.tensor(x_c[cc].values)\n",
    "                    )\n",
    "                    \n",
    "    def _get_log_likelihood(self, X):  # Override\n",
    "        log_lk = []\n",
    "\n",
    "        for c in range(self._num_cls):\n",
    "            lps = []\n",
    "\n",
    "            lps.extend([\n",
    "                dist.Normal(v['mu'][c], v['sigma'][c]).log_prob(torch.tensor(X[nc].values))\n",
    "                for nc, v in self._num_probs.items()\n",
    "            ])\n",
    "            \n",
    "            # Added\n",
    "            lps.extend([\n",
    "                dist.Categorical(logits=v[c]).log_prob(torch.tensor(X[cc].values))\n",
    "                for cc, v in self._cat_probs.items()\n",
    "            ])\n",
    "            # End Added\n",
    "\n",
    "            log_lk.append(torch.stack(lps).sum(dim=0))\n",
    "\n",
    "        return torch.stack(log_lk).t()\n",
    "    \n",
    "    # _observe_classes() from base class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 5 (0.2 + 0.2 + 0.2 pkt)\n",
    "\n",
    "Porównaj jakość działania różnych implementacji Naiwnego Bayesa (`scikit`, `pyro` oraz `pgmpy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "019d0ab2583cabc885267a475ebde88e",
     "grade": true,
     "grade_id": "cmc-scikit",
     "locked": false,
     "points": 0.2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.21      0.31        43\n",
      "           1       0.23      0.97      0.37        34\n",
      "           2       1.00      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.27       160\n",
      "   macro avg       0.60      0.40      0.23       160\n",
      "weighted avg       0.72      0.27      0.17       160\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50        10\n",
      "           1       0.25      0.89      0.39         9\n",
      "           2       1.00      0.10      0.17        21\n",
      "\n",
      "    accuracy                           0.35        40\n",
      "   macro avg       0.64      0.46      0.35        40\n",
      "weighted avg       0.75      0.35      0.30        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scikit \n",
    "\n",
    "clf_scikit = GaussianNB()\n",
    "clf_scikit.fit(X=cmc[\"train\"][\"X\"], y=cmc[\"train\"][\"y\"])\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    print(split)\n",
    "    print(sk_mtr.classification_report(\n",
    "        y_true=cmc[split][\"y\"],\n",
    "        y_pred=clf_scikit.predict(X=cmc[split][\"X\"]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b41d15e0077afcae143499186f7d675",
     "grade": true,
     "grade_id": "cmc-pyro",
     "locked": false,
     "points": 0.2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5830bf469c34cbb8cb2ca3ebbf7ef81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss = 91393.778\n",
      "Epoch: 100 Loss = 31051.077\n",
      "Epoch: 200 Loss = 20529.107\n",
      "Epoch: 300 Loss = 15777.805\n",
      "Epoch: 400 Loss = 12996.187\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.40      0.48        43\n",
      "           1       0.39      0.44      0.42        34\n",
      "           2       0.63      0.71      0.67        83\n",
      "\n",
      "    accuracy                           0.57       160\n",
      "   macro avg       0.54      0.52      0.52       160\n",
      "weighted avg       0.57      0.57      0.56       160\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44        10\n",
      "           1       0.44      0.44      0.44         9\n",
      "           2       0.65      0.71      0.68        21\n",
      "\n",
      "    accuracy                           0.57        40\n",
      "   macro avg       0.53      0.52      0.52        40\n",
      "weighted avg       0.57      0.57      0.57        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pyro\n",
    "clf_pyro = FullNBClassifier()\n",
    "clf_pyro.fit(X=cmc[\"train\"][\"X\"], y=cmc[\"train\"][\"y\"])\n",
    "\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    print(split)\n",
    "    print(sk_mtr.classification_report(\n",
    "        y_true=cmc[split][\"y\"],\n",
    "        y_pred=clf_pyro.predict(X=cmc[split][\"X\"]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4fdb119913e9e8e594aa5c45300144",
     "grade": true,
     "grade_id": "cmc-pgmpy",
     "locked": false,
     "points": 0.2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.40      0.48        43\n",
      "           1       0.42      0.56      0.48        34\n",
      "           2       0.62      0.65      0.64        83\n",
      "\n",
      "    accuracy                           0.56       160\n",
      "   macro avg       0.55      0.53      0.53       160\n",
      "weighted avg       0.57      0.56      0.56       160\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44        10\n",
      "           1       0.38      0.33      0.35         9\n",
      "           2       0.54      0.62      0.58        21\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.47      0.45      0.46        40\n",
      "weighted avg       0.49      0.50      0.49        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pgmpy\n",
    "# TU WPISZ KOD\n",
    "cmc_discrete = discretize_data(dataset=cmc, n_bins=5)\n",
    "clf_pgmpy = build_model(dataset=cmc_discrete)\n",
    "clf_pgmpy = fit_model(model=clf_pgmpy, training_data=cmc_discrete[\"train\"])\n",
    "\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    print(split)\n",
    "    print(sk_mtr.classification_report(\n",
    "        y_true=cmc_discrete[split][\"y\"],\n",
    "        y_pred=predict_pgmpy(model=clf_pgmpy, X=cmc_discrete[split][\"X\"]),\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
